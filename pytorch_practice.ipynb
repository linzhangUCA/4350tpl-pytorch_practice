{"cells":[{"cell_type":"markdown","metadata":{},"source":["# PyTorch Practice\n","**Due: Mondy, 10/24/2022, 2:15 PM**\n","\n","Welcome to your fifth assignment. You will create and train neural networks using a deep learning framework ([PyTorch](https://pytorch.org/)).\n","\n","Contents:\n","\n","1. (20%) Exercise 1: Load CIFAR10 Dataset\n","2. (10%) Exercise 2: Create Neural Network Model\n","4. (5%) Exerise 3.1: Build DataLoaders\n","5. (5%) Exercise 3.2: Training in One Epoch\n","6. (20%) Exercise 3.3: Training Iterations\n","7. (40%) Exercise 4: Custom Images Test\n","Instructions:\n","\n","- The code between the ### START CODE HERE ### and ### END CODE HERE ### comments will be graded.\n","- **Change variable names at your own risk. Make sure you understand what you are doing.**\n","- Avoid using for-loops and while-loops, unless you are explicitly asked to do so.\n","\n","**You will learn:**\n","- PyTorch built-in datasets.\n","- Create neural network models using `nn` module.\n","- Train neural network model with handy pre-defined loss functions and optimizers."]},{"cell_type":"markdown","metadata":{"id":"fyO57T9UIcgH"},"source":["\n","## Import Libraries\n","PyTorch has two [primitives to work with data](https://pytorch.org/docs/stable/data.html):\n","``torch.utils.data.DataLoader`` and ``torch.utils.data.Dataset``.\n","``Dataset`` stores the samples and their corresponding labels, and ``DataLoader`` wraps an iterable around\n","the ``Dataset``.\n","\n","**If you installed [PyTorch]((https://pytorch.org/get-started/locally/)) using Conda, you may want to [switch Python interpreter](https://code.visualstudio.com/docs/python/environments) to comply with the Conda environment that hosts PyTorch.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gAyJc1FoIcgJ"},"outputs":[],"source":["import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torchvision.io import read_image\n","from torchvision.transforms import ToTensor, Resize\n","import matplotlib.pyplot as plt\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"VuSHJ43BIcgK"},"source":["## 1 - Load Dateset\n","#### **(20%) Exercise 1**: Load CIFAR10 Dataset\n","Load CIFAR10 dataset from TorchVision datasets. \n","1. Create a training dataset.\n","2. Create a test dataset.\n","3. Inspect the training dataset.\n","4. Visualize samples from the training dataset.\n","\n","> **Hint:** \n","Usually, an image is numerically represented by `(# height pixels, # width pixels, # color channels)`. PyTorch, however, represents an image with a different order `(# color channels, # height pixels, # width pixels)`. You may find `torch.permute()` function useful if trying to show pictures in `Matplotlib`. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8fpoJniAIcgL"},"outputs":[],"source":["# Create datasets\n","### START CODE HERE ###\n","training_data = None  # Create training data from open datasets.\n","test_data = None  # Create test data from open datasets.\n","### END CODE HERE ###\n","\n","\n","# Investigate datasets\n","### START CODE HERE ###\n","num_train = None  # number of training examples\n","res_train = None  # training image resolution\n","num_test = None  # number of test examples   \n","res_test = None  # test image resolution\n","### END CODE HERE ###\n","\n","print(f\"number of training examples: {num_train}\")\n","print(f\"training image resolution (CHANNEL, HEIGHT, WIDTH): {res_train}\")\n","print(f\"number of test examples: {num_test}\")\n","print(f\"test image resolution (CHANNEL, HEIGHT, WIDTH): {res_test}\")\n","\n","\n","# Visulization\n","labels_map = {\n","    0: 'airplane',\n","    1: 'automobile',\n","    2: 'bird',\n","    3: 'cat',\n","    4: 'deer',\n","    5: 'dog',\n","    6: 'frog',\n","    7: 'horse',\n","    8: 'ship',\n","    9: 'truck',\n","}\n","figure = plt.figure(figsize=(8, 8))\n","cols, rows = 3, 3\n","for i in range(1, cols * rows + 1):\n","    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n","    ### START CODE HERE ###\n","    img, label = None\n","    img_perm = None  # you may want to permute order of the axes in img\n","    ### END CODE HERE ###\n","    figure.add_subplot(rows, cols, i)\n","    plt.title(labels_map[label])\n","    plt.axis(\"off\")\n","    plt.imshow(img_perm.squeeze(), cmap=\"gray\")\n"]},{"cell_type":"markdown","metadata":{},"source":["> **Expected Results:**\n","```console\n","number of training examples: 50000\n","training image resolution (CHANNEL, HEIGHT, WIDTH): torch.Size([3, 32, 32])\n","number of test examples: 10000\n","test image resolution (CHANNEL, HEIGHT, WIDTH): torch.Size([3, 32, 32])\n","```\n"]},{"cell_type":"markdown","metadata":{},"source":["--------------\n"]},{"cell_type":"markdown","metadata":{"id":"w9ZKhUImIcgR"},"source":["## 2 - Build the Model\n","#### **(10%) Exercise 2**: Create Neural Network Model\n","Define a neural network model class from [nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html). The NN model contains 3 layers (2 hidden layers and 1 output layer).\n","- Define the layers of the model in `__init__` function (define a helper function: `flatten`).\n","- Define how data will pass through the model in the `forward` function (use `flatten` function to reshape the inputs). \n","- (Optional) Move the operations to GPU if available.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C95DaIoSIcgS","outputId":"8ea12c8d-3608-4cec-827e-d449fde84302"},"outputs":[],"source":["class NeuralNetwork(nn.Module):\n","\n","    def __init__(self, hidden_layer_sizes):\n","        \"\"\"\n","        Structure of the neural network model\n","\n","        Arguments:\n","            hiddent_layer_sizes -- python list, contains two values to indicate number of neurons in the first and second hiddent layer\n","        \"\"\"\n","\n","        super().__init__()\n","        self.flatten = nn.Flatten()\n","        ### START CODE HERE ###\n","        self.linear_relu_stack = None\n","        ### END CODE HERE ###\n","    \n","    def forward(self, inputs):\n","        ### START CODE HERE ###\n","        x = None\n","        logits = None\n","        ### END CODE HERE ###\n","    \n","        return logits\n","\n","\n","# Test/Usage\n","model = NeuralNetwork([100, 200])\n","print(model)\n","\n","X = torch.rand(1, 3, 32, 32)\n","logits = model(X)  # DO NOT call model.forward()\n","pred_probab = nn.Softmax(dim=1)(logits)\n","y_pred = pred_probab.argmax(1)\n","print(f\"Predicted probabilities: \\n{pred_probab}\")\n","print(f\"Predicted classes: {y_pred}: {labels_map[int(y_pred)]}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["> **Expected:**\n","```console\n","NeuralNetwork(\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (linear_relu_stack): Sequential(\n","    (0): Linear(in_features=3072, out_features=100, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=100, out_features=200, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=200, out_features=10, bias=True)\n","  )\n",")\n","Predicted probabilities: \n","tensor([[0.0893, 0.0994, 0.0983, 0.0990, 0.0937, 0.0988, 0.1027, 0.1051, 0.1146,\n","         0.0991]], grad_fn=<SoftmaxBackward0>)\n","Predicted classes: tensor([8]): ship\n","```"]},{"cell_type":"markdown","metadata":{"id":"B5aW2QWlIcgS"},"source":["> To use the model, we pass it the input data. This executes the modelâ€™s `forward`, along with some [background operations](https://github.com/pytorch/pytorch/blob/270111b7b611d174967ed204776985cefca9c144/torch/nn/modules/module.py#L866). Do not call `model.forward()` directly!\n","\n","> Calling the model on the input returns a 2-dimensional tensor with dim=0 corresponding to each output of 10 raw predicted values for each class, and dim=1 corresponding to the individual values of each output. We get the prediction probabilities by passing it through an instance of the `nn.Softmax` module.\n","\n","> Read more about [building neural networks in PyTorch](https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html).\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"w2LELznUIcgU"},"source":["--------------\n"]},{"cell_type":"markdown","metadata":{"id":"QTVRPcczIcgU"},"source":["## 3- Optimize the Model Parameters\n","\n","#### **(5%) Exercise 3.1**: Build DataLoaders\n","Pass the `Dataset` as an argument to `DataLoader`. This wraps an iterable over the dataset, and supports\n","automatic batching, sampling, shuffling and multiprocess data loading. \n","- Create a `DataLoader` for `training_data` with default batch size of 64.\n","- Create a `DataLoader` for `test_data` with default batch size of 64.\n","\n","> **Update the `batch_size` later if needed**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["### START CODE HERE ###\n","train_dataloader = None\n","test_dataloader = None\n","### END CODE HERE ###\n","\n","\n","# Test\n","i = 1\n","for X, y in test_dataloader:\n","    print(f\"Shape of X in batch {i} [N, C, H, W]: {X.shape}\")\n","    print(f\"Shape of y in batch {i}: {y.shape} {y.dtype}\")\n","    i += 1\n","    # break\n"]},{"cell_type":"markdown","metadata":{},"source":["> **Expected:**\n","```console\n","Shape of X in batch 1 [N, C, H, W]: torch.Size([64, 3, 32, 32])\n","Shape of y in batch 1: torch.Size([64]) torch.int64\n","Shape of X in batch 2 [N, C, H, W]: torch.Size([64, 3, 32, 32])\n","Shape of y in batch 2: torch.Size([64]) torch.int64\n","...\n","Shape of X in batch 156 [N, C, H, W]: torch.Size([64, 3, 32, 32])\n","Shape of y in batch 156: torch.Size([64]) torch.int64\n","Shape of X in batch 157 [N, C, H, W]: torch.Size([16, 3, 32, 32])\n","Shape of y in batch 157: torch.Size([16]) torch.int64\n","```\n"]},{"cell_type":"markdown","metadata":{"id":"Toyg9mN3IcgV"},"source":["#### **(5%) Exercise 3.2**: Training in One Epoch\n","Define the `train` function to loop all the batches in the DataLoader. In a single training loop, \n","1. the model makes predictions on the training minibatches: `model(inputs)`, \n","2. compute prediction error: `loss_fn(predictions, labels)`,\n","3. backpropagate to obtain the gradients of the model's parameters: `loss.backward()`,\n","4. update the model's parameters with the specified optimizer: `optimizer.step()`,\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6kLHCs0EIcgV"},"outputs":[],"source":["def train(dataloader, model, loss_fn, optimizer):\n","    size = len(dataloader.dataset)\n","    model.train()\n","    for batch, (X, y) in enumerate(dataloader):\n","        # Compute prediction error\n","        ### START CODE HERE ###\n","        pred = None  # forward propagation\n","        loss = None  # compute loss\n","        optimizer.zero_grad()  # zero previous gradient\n","        None  # back propagatin\n","        None  # update parameters\n","        ### END CODE HERE ###\n","        if batch % 100 == 0:\n","            loss, current = loss.item(), batch * len(X)\n","            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n","\n","\n","# Define a test function to evaluate model performance\n","def test(dataloader, model, loss_fn):\n","    size = len(dataloader.dataset)\n","    num_batches = len(dataloader)\n","    model.eval()\n","    test_loss, accuracy = 0, 0\n","    with torch.no_grad():\n","        for X, y in dataloader:\n","            # X, y = X.to(device), y.to(device)\n","            pred = model(X)\n","            test_loss += loss_fn(pred, y).item()\n","            accuracy += (pred.argmax(1) == y).type(torch.float).sum().item()\n","    test_loss /= num_batches\n","    accuracy /= size\n","    print(f\"Test Error: \\n Accuracy: {(100*accuracy):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n","\n","    return accuracy\n"]},{"cell_type":"markdown","metadata":{},"source":["#### **(20%) Exercise 3.3**: Training Iterations\n","The training process is conducted over several iterations (*epochs*). During each epoch, the model learns\n","parameters to make better predictions. Log the model's accuracy and loss at each epoch; we'd like to see the\n","accuracy increase and the loss decrease with every epoch.\n","\n","To start a training process:\n","1. initialize neural network model with your choice of hidden layer sizes,\n","2. define cross-entropy loss function,\n","3. specify Adam optimizer with your choice of learning rate to update the model's parameters,\n","4. set total number of training epochs.\n","\n","You are expected to obtain a growing accuracy curve. \n","> **Hint:**\n","> - Feel free to change whatever hyperparameters to increase the test accuracy\n","> - You can choose different `batch_size`"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Start training\n","### START CODE HERE ###\n","cifar_model = None\n","loss_fn = None\n","optimizer = None\n","epochs = None\n","### END CODE HERE ###\n","test_acc = []\n","for t in range(epochs):\n","    print(f\"Epoch {t+1}\\n-------------------------------\")\n","    train(train_dataloader, cifar_model, loss_fn, optimizer)\n","    acc = test(test_dataloader, cifar_model, loss_fn)\n","    test_acc.append(acc)\n","print(\"Done!\")\n","\n","\n","plt.plot(test_acc)\n"]},{"cell_type":"markdown","metadata":{"id":"qY-z6wgJIcgY"},"source":["--------------\n"]},{"cell_type":"markdown","metadata":{"id":"87yQW0tAIcgZ"},"source":["## 4 - Evaluation\n","This model can now be used to make predictions. You can change the index of the test example from `test_data` in the following block. \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"18koQ2NcIcga","outputId":"5a26d21b-67d2-47cc-b358-c394187996e5"},"outputs":[],"source":["cifar_model.eval()\n","x, y = test_data[4][0], test_data[4][1]\n","x = x.unsqueeze(dim=0)\n","with torch.no_grad():\n","    pred = cifar_model(x)\n","    predicted, actual = labels_map[int(pred[0].argmax(0))], labels_map[y]\n","    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')\n","plt.imshow(x.squeeze().permute(1, 2, 0), cmap=\"gray\")\n"]},{"cell_type":"markdown","metadata":{},"source":["#### **(40%) Exercise 4**: Test Custom Images\n","Upload 10 custom pictures to the `images/` directory, one picture for each class. Evaluate and observe the predicted results with the trained model and newly uploaded pictures.   \n","\n","> ***Hints:*\n","> - To read a image as a torch tensor, check out [`torchvision.io.read_image()`](https://pytorch.org/vision/stable/generated/torchvision.io.read_image.html#torchvision.io.read_image) function.\n","> - To resize a torch tensor (image), check out ['torchvision.transforms.Resize'](https://pytorch.org/vision/main/generated/torchvision.transforms.Resize.html) class or [this tutorial](https://www.tutorialspoint.com/pytorch-how-to-resize-an-image-to-a-given-size).\n","> - Images named after `class name.jpg` pattern would be easier to use. For example: `frog.jpg` and `ship.jpg`.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","figure = plt.figure()\n","cols, rows = 2, 5\n","resize = Resize((32, 32))\n","for i in range(1, cols * rows + 1):\n","    ### START CODE HERE ###\n","    img = None  # read image to tensor\n","    img_resize = None # resize image to fit in the nn model\n","    pred = None  # make prediction\n","    img_perm = None  # permute image axes to compatible with matplotlib\n","    ### END CODE HERE ###\n","    figure.add_subplot(rows, cols, i)\n","    plt.title('label:' + labels_map[i-1] + '\\tprediction:' + labels_map[pred])\n","    plt.axis(\"off\")\n","    plt.imshow(img_perm.squeeze(), cmap=\"gray\")\n"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3.9.13 ('torch')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"111bb55a258b144f6b1581aab35d5df936e18e3736a3cb72eecdb230991dcee8"}}},"nbformat":4,"nbformat_minor":0}
